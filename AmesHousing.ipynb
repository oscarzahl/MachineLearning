{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c1be10f-6573-42e6-8b71-a9489efa0789",
   "metadata": {},
   "source": [
    "<h3>1. Introduction</h3>\n",
    "In this project, my goal is to predict house sale prices in the Ames housing dataset using various regression techniques. The dataset contains a broad range of features describing different aspects of each property, such as neighborhood, lot area, basement condition, garage type, and more. By analyzing and modeling this data, I aim to create a predictive model that can accurately estimate the sale price of a house. I will explore several regression models, including Linear Regression, Polynomial Regression, and Ensemble Models (Random Forest and Gradient Boosting), to determine which approach best captures the underlying patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32e3a4d-fbc9-4a4f-84a7-d525ad082e0f",
   "metadata": {},
   "source": [
    "<h4>Import Libraries</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "988cf97a-2aac-44f3-8b19-99401e83dba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ec6590-7323-4d43-a73b-05ea0e4893df",
   "metadata": {},
   "source": [
    "<h3>2. Data Exploration and Preprocessing</h3>\n",
    "<h4>Data Exploration</h4>\n",
    "I started by loading the Ames housing dataset and examining its structure. This dataset includes 2,930 rows and 82 columns, consisting of both numerical and categorical features that describe various characteristics of each property, including the neighborhood, lot area, and conditions of different parts of the house (like basements, garages, and kitchens).\n",
    "\n",
    "Key data exploration steps included:\n",
    "\n",
    " - Checking Missing Values: Many features, such as Lot Frontage, Alley, and Garage Type, contained missing values. Some features, like Pool QC (pool quality), had very few non-null values, suggesting that they were irrelevant for most houses.\n",
    " - Understanding Data Types: Features were categorized as numerical (e.g., Lot Area, SalePrice) or categorical (e.g., Neighborhood, House Style).\n",
    " - Summary Statistics: Using .describe(), I obtained insights into distributions, ranges, and potential outliers, which informed decisions on scaling and potential outlier handling.\n",
    "\n",
    "After the initial exploration, I determined that several preprocessing steps were needed to make the data suitable for regression modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "6acc4332-42f9-466e-af59-13025f307727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2930 entries, 0 to 2929\n",
      "Data columns (total 82 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Order            2930 non-null   int64  \n",
      " 1   PID              2930 non-null   int64  \n",
      " 2   MS SubClass      2930 non-null   int64  \n",
      " 3   MS Zoning        2930 non-null   object \n",
      " 4   Lot Frontage     2440 non-null   float64\n",
      " 5   Lot Area         2930 non-null   int64  \n",
      " 6   Street           2930 non-null   object \n",
      " 7   Alley            198 non-null    object \n",
      " 8   Lot Shape        2930 non-null   object \n",
      " 9   Land Contour     2930 non-null   object \n",
      " 10  Utilities        2930 non-null   object \n",
      " 11  Lot Config       2930 non-null   object \n",
      " 12  Land Slope       2930 non-null   object \n",
      " 13  Neighborhood     2930 non-null   object \n",
      " 14  Condition 1      2930 non-null   object \n",
      " 15  Condition 2      2930 non-null   object \n",
      " 16  Bldg Type        2930 non-null   object \n",
      " 17  House Style      2930 non-null   object \n",
      " 18  Overall Qual     2930 non-null   int64  \n",
      " 19  Overall Cond     2930 non-null   int64  \n",
      " 20  Year Built       2930 non-null   int64  \n",
      " 21  Year Remod/Add   2930 non-null   int64  \n",
      " 22  Roof Style       2930 non-null   object \n",
      " 23  Roof Matl        2930 non-null   object \n",
      " 24  Exterior 1st     2930 non-null   object \n",
      " 25  Exterior 2nd     2930 non-null   object \n",
      " 26  Mas Vnr Type     1155 non-null   object \n",
      " 27  Mas Vnr Area     2907 non-null   float64\n",
      " 28  Exter Qual       2930 non-null   object \n",
      " 29  Exter Cond       2930 non-null   object \n",
      " 30  Foundation       2930 non-null   object \n",
      " 31  Bsmt Qual        2850 non-null   object \n",
      " 32  Bsmt Cond        2850 non-null   object \n",
      " 33  Bsmt Exposure    2847 non-null   object \n",
      " 34  BsmtFin Type 1   2850 non-null   object \n",
      " 35  BsmtFin SF 1     2929 non-null   float64\n",
      " 36  BsmtFin Type 2   2849 non-null   object \n",
      " 37  BsmtFin SF 2     2929 non-null   float64\n",
      " 38  Bsmt Unf SF      2929 non-null   float64\n",
      " 39  Total Bsmt SF    2929 non-null   float64\n",
      " 40  Heating          2930 non-null   object \n",
      " 41  Heating QC       2930 non-null   object \n",
      " 42  Central Air      2930 non-null   object \n",
      " 43  Electrical       2929 non-null   object \n",
      " 44  1st Flr SF       2930 non-null   int64  \n",
      " 45  2nd Flr SF       2930 non-null   int64  \n",
      " 46  Low Qual Fin SF  2930 non-null   int64  \n",
      " 47  Gr Liv Area      2930 non-null   int64  \n",
      " 48  Bsmt Full Bath   2928 non-null   float64\n",
      " 49  Bsmt Half Bath   2928 non-null   float64\n",
      " 50  Full Bath        2930 non-null   int64  \n",
      " 51  Half Bath        2930 non-null   int64  \n",
      " 52  Bedroom AbvGr    2930 non-null   int64  \n",
      " 53  Kitchen AbvGr    2930 non-null   int64  \n",
      " 54  Kitchen Qual     2930 non-null   object \n",
      " 55  TotRms AbvGrd    2930 non-null   int64  \n",
      " 56  Functional       2930 non-null   object \n",
      " 57  Fireplaces       2930 non-null   int64  \n",
      " 58  Fireplace Qu     1508 non-null   object \n",
      " 59  Garage Type      2773 non-null   object \n",
      " 60  Garage Yr Blt    2771 non-null   float64\n",
      " 61  Garage Finish    2771 non-null   object \n",
      " 62  Garage Cars      2929 non-null   float64\n",
      " 63  Garage Area      2929 non-null   float64\n",
      " 64  Garage Qual      2771 non-null   object \n",
      " 65  Garage Cond      2771 non-null   object \n",
      " 66  Paved Drive      2930 non-null   object \n",
      " 67  Wood Deck SF     2930 non-null   int64  \n",
      " 68  Open Porch SF    2930 non-null   int64  \n",
      " 69  Enclosed Porch   2930 non-null   int64  \n",
      " 70  3Ssn Porch       2930 non-null   int64  \n",
      " 71  Screen Porch     2930 non-null   int64  \n",
      " 72  Pool Area        2930 non-null   int64  \n",
      " 73  Pool QC          13 non-null     object \n",
      " 74  Fence            572 non-null    object \n",
      " 75  Misc Feature     106 non-null    object \n",
      " 76  Misc Val         2930 non-null   int64  \n",
      " 77  Mo Sold          2930 non-null   int64  \n",
      " 78  Yr Sold          2930 non-null   int64  \n",
      " 79  Sale Type        2930 non-null   object \n",
      " 80  Sale Condition   2930 non-null   object \n",
      " 81  SalePrice        2930 non-null   int64  \n",
      "dtypes: float64(11), int64(28), object(43)\n",
      "memory usage: 1.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Overall Qual</th>\n",
       "      <th>Overall Cond</th>\n",
       "      <th>Year Built</th>\n",
       "      <th>Year Remod/Add</th>\n",
       "      <th>Mas Vnr Area</th>\n",
       "      <th>...</th>\n",
       "      <th>Wood Deck SF</th>\n",
       "      <th>Open Porch SF</th>\n",
       "      <th>Enclosed Porch</th>\n",
       "      <th>3Ssn Porch</th>\n",
       "      <th>Screen Porch</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2930.00000</td>\n",
       "      <td>2.930000e+03</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2440.000000</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2907.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2930.000000</td>\n",
       "      <td>2930.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1465.50000</td>\n",
       "      <td>7.144645e+08</td>\n",
       "      <td>57.387372</td>\n",
       "      <td>69.224590</td>\n",
       "      <td>10147.921843</td>\n",
       "      <td>6.094881</td>\n",
       "      <td>5.563140</td>\n",
       "      <td>1971.356314</td>\n",
       "      <td>1984.266553</td>\n",
       "      <td>101.896801</td>\n",
       "      <td>...</td>\n",
       "      <td>93.751877</td>\n",
       "      <td>47.533447</td>\n",
       "      <td>23.011604</td>\n",
       "      <td>2.592491</td>\n",
       "      <td>16.002048</td>\n",
       "      <td>2.243345</td>\n",
       "      <td>50.635154</td>\n",
       "      <td>6.216041</td>\n",
       "      <td>2007.790444</td>\n",
       "      <td>180796.060068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>845.96247</td>\n",
       "      <td>1.887308e+08</td>\n",
       "      <td>42.638025</td>\n",
       "      <td>23.365335</td>\n",
       "      <td>7880.017759</td>\n",
       "      <td>1.411026</td>\n",
       "      <td>1.111537</td>\n",
       "      <td>30.245361</td>\n",
       "      <td>20.860286</td>\n",
       "      <td>179.112611</td>\n",
       "      <td>...</td>\n",
       "      <td>126.361562</td>\n",
       "      <td>67.483400</td>\n",
       "      <td>64.139059</td>\n",
       "      <td>25.141331</td>\n",
       "      <td>56.087370</td>\n",
       "      <td>35.597181</td>\n",
       "      <td>566.344288</td>\n",
       "      <td>2.714492</td>\n",
       "      <td>1.316613</td>\n",
       "      <td>79886.692357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>5.263011e+08</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>12789.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>733.25000</td>\n",
       "      <td>5.284770e+08</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>7440.250000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1965.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>129500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1465.50000</td>\n",
       "      <td>5.354536e+08</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>9436.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>160000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2197.75000</td>\n",
       "      <td>9.071811e+08</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11555.250000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2001.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>213500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2930.00000</td>\n",
       "      <td>1.007100e+09</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1424.000000</td>\n",
       "      <td>742.000000</td>\n",
       "      <td>1012.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Order           PID  MS SubClass  Lot Frontage       Lot Area  \\\n",
       "count  2930.00000  2.930000e+03  2930.000000   2440.000000    2930.000000   \n",
       "mean   1465.50000  7.144645e+08    57.387372     69.224590   10147.921843   \n",
       "std     845.96247  1.887308e+08    42.638025     23.365335    7880.017759   \n",
       "min       1.00000  5.263011e+08    20.000000     21.000000    1300.000000   \n",
       "25%     733.25000  5.284770e+08    20.000000     58.000000    7440.250000   \n",
       "50%    1465.50000  5.354536e+08    50.000000     68.000000    9436.500000   \n",
       "75%    2197.75000  9.071811e+08    70.000000     80.000000   11555.250000   \n",
       "max    2930.00000  1.007100e+09   190.000000    313.000000  215245.000000   \n",
       "\n",
       "       Overall Qual  Overall Cond   Year Built  Year Remod/Add  Mas Vnr Area  \\\n",
       "count   2930.000000   2930.000000  2930.000000     2930.000000   2907.000000   \n",
       "mean       6.094881      5.563140  1971.356314     1984.266553    101.896801   \n",
       "std        1.411026      1.111537    30.245361       20.860286    179.112611   \n",
       "min        1.000000      1.000000  1872.000000     1950.000000      0.000000   \n",
       "25%        5.000000      5.000000  1954.000000     1965.000000      0.000000   \n",
       "50%        6.000000      5.000000  1973.000000     1993.000000      0.000000   \n",
       "75%        7.000000      6.000000  2001.000000     2004.000000    164.000000   \n",
       "max       10.000000      9.000000  2010.000000     2010.000000   1600.000000   \n",
       "\n",
       "       ...  Wood Deck SF  Open Porch SF  Enclosed Porch   3Ssn Porch  \\\n",
       "count  ...   2930.000000    2930.000000     2930.000000  2930.000000   \n",
       "mean   ...     93.751877      47.533447       23.011604     2.592491   \n",
       "std    ...    126.361562      67.483400       64.139059    25.141331   \n",
       "min    ...      0.000000       0.000000        0.000000     0.000000   \n",
       "25%    ...      0.000000       0.000000        0.000000     0.000000   \n",
       "50%    ...      0.000000      27.000000        0.000000     0.000000   \n",
       "75%    ...    168.000000      70.000000        0.000000     0.000000   \n",
       "max    ...   1424.000000     742.000000     1012.000000   508.000000   \n",
       "\n",
       "       Screen Porch    Pool Area      Misc Val      Mo Sold      Yr Sold  \\\n",
       "count   2930.000000  2930.000000   2930.000000  2930.000000  2930.000000   \n",
       "mean      16.002048     2.243345     50.635154     6.216041  2007.790444   \n",
       "std       56.087370    35.597181    566.344288     2.714492     1.316613   \n",
       "min        0.000000     0.000000      0.000000     1.000000  2006.000000   \n",
       "25%        0.000000     0.000000      0.000000     4.000000  2007.000000   \n",
       "50%        0.000000     0.000000      0.000000     6.000000  2008.000000   \n",
       "75%        0.000000     0.000000      0.000000     8.000000  2009.000000   \n",
       "max      576.000000   800.000000  17000.000000    12.000000  2010.000000   \n",
       "\n",
       "           SalePrice  \n",
       "count    2930.000000  \n",
       "mean   180796.060068  \n",
       "std     79886.692357  \n",
       "min     12789.000000  \n",
       "25%    129500.000000  \n",
       "50%    160000.000000  \n",
       "75%    213500.000000  \n",
       "max    755000.000000  \n",
       "\n",
       "[8 rows x 39 columns]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"AmesHousing.csv\")\n",
    "data.head()\n",
    "data.info()  # This provides an overview of data types and missing values\n",
    "data.describe()  # Summary statistics of numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "f56a2cbf-84ed-4607-a0a0-5bc0fc065668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Order               0\n",
       "PID                 0\n",
       "MS SubClass         0\n",
       "MS Zoning           0\n",
       "Lot Frontage      490\n",
       "                 ... \n",
       "Mo Sold             0\n",
       "Yr Sold             0\n",
       "Sale Type           0\n",
       "Sale Condition      0\n",
       "SalePrice           0\n",
       "Length: 78, dtype: int64"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns = data.columns.str.strip()\n",
    "data = data.drop(columns=['Alley', 'Pool QC', 'Fence', 'Misc Feature'])\n",
    "data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65978c2-c4d4-45e7-b4cc-6f8df762563a",
   "metadata": {},
   "source": [
    "<h4>Data Preprocessing</h4>\n",
    "To prepare the data, I applied the following transformations:\n",
    "\n",
    "1. Handling Missing Values:\n",
    "   - Numerical Features: For numerical columns with moderate amounts of missing data (e.g., Lot Frontage, Mas Vnr Area), I filled missing values with the median, as this approach minimizes the impact of extreme values.\n",
    "   - Basement and Garage Features: Features related to the basement (BsmtFin SF 1, Bsmt Full Bath, etc.) and garage (Garage Yr Blt, Garage Cars, etc.) were set to 0 where missing values indicated the absence of that feature. This allowed us to distinguish between homes with and without these amenities.\n",
    "   - Categorical Features: Missing values in categorical columns (e.g., Garage Type, Bsmt Qual) were filled with \"Unknown\" to indicate the lack of information. This approach ensures no data is lost due to missing values.\n",
    "\n",
    "2. Encoding Categorical Variables:\n",
    "\n",
    "   - I applied One-Hot Encoding to convert categorical variables into a numerical format, creating binary columns for each category. This encoding allows models to interpret categorical information effectively without introducing multicollinearity. The drop_first=True option was used to reduce redundancy.\n",
    "\n",
    "3. Feature Scaling:\n",
    "\n",
    "   - Using StandardScaler, I standardized numerical columns to have a mean of 0 and a standard deviation of 1. Scaling improves the performance of certain models, particularly Polynomial Regression, by ensuring that all features contribute equally to the model.\n",
    "\n",
    "4. Splitting Data into Training and Testing Sets:\n",
    "\n",
    "   - Finally, I split the dataset into training and testing sets, with 80% of the data allocated for training and 20% for testing. This split enables model evaluation on unseen data to assess generalizability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "c9f58ea2-5bff-4e03-89a3-7293ff7ef384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in X_train: 0\n",
      "Missing values in X_test: 0\n",
      "Columns with missing values in X_train:\n",
      " Series([], dtype: int64)\n",
      "Columns with missing values in X_test:\n",
      " Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Fill Lot Frontage and Mas Vnr Area with their median values\n",
    "data['Lot Frontage'] = data['Lot Frontage'].fillna(data['Lot Frontage'].median())\n",
    "data['Mas Vnr Area'] = data['Mas Vnr Area'].fillna(data['Mas Vnr Area'].median())\n",
    "\n",
    "# Fill Garage-related columns with 0 where there is likely no garage\n",
    "data['Garage Yr Blt'] = data['Garage Yr Blt'].fillna(0)\n",
    "data['Garage Cars'] = data['Garage Cars'].fillna(0)\n",
    "data['Garage Area'] = data['Garage Area'].fillna(0)\n",
    "\n",
    "# Fill Basement-related columns with 0 where there is likely no basement\n",
    "basement_cols = ['BsmtFin SF 1', 'BsmtFin SF 2', 'Bsmt Unf SF', \n",
    "                 'Total Bsmt SF', 'Bsmt Full Bath', 'Bsmt Half Bath']\n",
    "data[basement_cols] = data[basement_cols].fillna(0)\n",
    "\n",
    "# Fill categorical columns with 'Unknown'\n",
    "categorical_cols_with_missing = ['Garage Type', 'Garage Finish', 'Garage Qual', 'Garage Cond', 'Bsmt Qual', \n",
    "                                 'Bsmt Cond', 'Bsmt Exposure', 'BsmtFin Type 1', 'BsmtFin Type 2', 'Electrical']\n",
    "\n",
    "for col in categorical_cols_with_missing:\n",
    "    data[col] = data[col].fillna(\"Unknown\")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Missing values in X_train:\", X_train.isnull().sum().sum())\n",
    "print(\"Missing values in X_test:\", X_test.isnull().sum().sum())\n",
    "\n",
    "print(\"Columns with missing values in X_train:\\n\", X_train.isnull().sum()[X_train.isnull().sum() > 0])\n",
    "print(\"Columns with missing values in X_test:\\n\", X_test.isnull().sum()[X_test.isnull().sum() > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "5d337e91-9263-47da-9240-7298df1d9ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, drop_first=True)\n",
    "\n",
    "# Select only numerical columns (e.g., float and integer types)\n",
    "numerical_cols = data.select_dtypes(include=['float64', 'int64']).columns\n",
    "scaler = StandardScaler()\n",
    "data[numerical_cols] = scaler.fit_transform(data[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "ab11b257-498c-45e4-a4a5-039edcc3f870",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = data.drop(columns=['SalePrice'])  # Features\n",
    "y = data['SalePrice']  # Target variable\n",
    "\n",
    "\n",
    "# Split data into 80% training and 20% testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18649d2c-185b-415b-b441-8b9b5f0e96b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<h3>3. Model Implementation</h3>\n",
    "I implemented four regression models to predict house prices. Here’s a brief description of each model, why it was chosen, and the code used for training and evaluating them:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b634bb-f36b-421a-989e-013f5cdcfa46",
   "metadata": {},
   "source": [
    "<h3>Linear Regression</h3> \n",
    "Linear Regression is a straightforward model that assumes a linear relationship between features and the target variable. I used it as a baseline model to see how a simple, linear approach performs on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "72e01c8e-c7a4-4ffe-8a49-8ea8bbc2fbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Performance:\n",
      "MAE: 826599.6214399436\n",
      "MSE: 400296536895215.4\n",
      "RMSE: 20007412.048918653\n",
      "R² Score: -318523074565158.25\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_lr = linear_model.predict(X_test)\n",
    "\n",
    "print(\"Linear Regression Performance:\")\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred_lr))\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred_lr))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_lr)))\n",
    "print(\"R² Score:\", r2_score(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72da751e-ed1b-451e-b9d5-96e824e5f0c9",
   "metadata": {},
   "source": [
    "<h3>Polynomial Regression</h3>\n",
    "Polynomial Regression allows us to capture non-linear relationships by adding polynomial terms (e.g., squares and interactions of features). I used a degree-2 polynomial to see if introducing non-linearity would improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "0664a859-8d96-4acd-9fb2-a73af465104c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Polynomial Regression Performance:\n",
      "MAE: 0.32850972574011694\n",
      "MSE: 0.2976051863808963\n",
      "RMSE: 0.5455320214074479\n",
      "R² Score: 0.7631902596314633\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "poly_model = LinearRegression()\n",
    "poly_model.fit(X_train_poly, y_train)\n",
    "y_pred_poly = poly_model.predict(X_test_poly)\n",
    "\n",
    "\n",
    "print(\"\\nPolynomial Regression Performance:\")\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred_poly))\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred_poly))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_poly)))\n",
    "print(\"R² Score:\", r2_score(y_test, y_pred_poly))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b444d0-c164-44b1-a1c1-d5df0af54a59",
   "metadata": {},
   "source": [
    "<h3>Random Forest Regressor</h3>\n",
    "Random Forest is an ensemble model that builds multiple decision trees and averages their predictions, making it more robust to overfitting and capable of handling non-linear relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "c6cb0175-4ffa-4c76-a9d3-f19a5450aab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Regression Performance:\n",
      "MAE: 0.1987152005718906\n",
      "MSE: 0.10830290975308667\n",
      "RMSE: 0.3290940743208341\n",
      "R² Score: 0.9138214483031205\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\"\\nRandom Forest Regression Performance:\")\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred_rf))\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred_rf))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_rf)))\n",
    "print(\"R² Score:\", r2_score(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662d6e8b-feb4-4cc2-8f0d-18ce4cd4dd72",
   "metadata": {},
   "source": [
    "<h3>Gradient Boosting Regressor</h3>\n",
    "Gradient Boosting is another ensemble method that builds models sequentially to minimize errors from previous models. This makes it very effective at capturing complex patterns and typically results in high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "89bec7ed-486c-4a4c-9905-282daca0eac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting Regression Performance:\n",
      "MAE: 0.1901368392586956\n",
      "MSE: 0.0971957414359103\n",
      "RMSE: 0.311762315612247\n",
      "R² Score: 0.9226596196986074\n"
     ]
    }
   ],
   "source": [
    "gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "print(\"\\nGradient Boosting Regression Performance:\")\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred_gb))\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred_gb))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_gb)))\n",
    "print(\"R² Score:\", r2_score(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea82bbc-95c3-4e09-9f38-dac6d1215b78",
   "metadata": {},
   "source": [
    "<h3>4. Model Evaluation and Comparison</h3>\n",
    "\n",
    "To evaluate each model, I used the following metrics:\n",
    " - Mean Absolute Error (MAE): Average absolute difference between predicted and actual prices.\n",
    " - Mean Squared Error (MSE): Average squared difference between predicted and actual prices, penalizing larger errors.\n",
    " - Root Mean Squared Error (RMSE): Square root of MSE, providing an interpretable metric in the same units as the target.\n",
    " - R² Score: Indicates how well the model explains the variance in the target variable.\n",
    "\n",
    "<h4>Performance Summary:</h4>\n",
    "\n",
    " - Linear Regression: This model performed poorly, with very high MAE, MSE, and RMSE values, and a negative R² score. This indicates that the simple linear approach was not able to capture the complexity of the data, likely due to non-linear relationships among features.\n",
    "\n",
    " - Polynomial Regression: By adding polynomial terms, this model showed a significant improvement, with lower error metrics and an R² score of 0.76. However, it still left some variance unexplained, suggesting that a non-parametric model might perform better.\n",
    "\n",
    " - Random Forest Regression: The ensemble approach of Random Forest yielded much better performance, with a high R² score of 0.91 and low MAE and RMSE values. This model captured non-linear relationships well and handled complex interactions between features effectively.\n",
    "\n",
    " - Gradient Boosting Regression: Gradient Boosting outperformed all other models, with the lowest error metrics and an R² score of 0.92. Its sequential learning approach allowed it to make highly accurate predictions.\n",
    "\n",
    "<h4>Chosen Model:</h4> \n",
    "Based on these evaluations, Gradient Boosting Regression is the best model for predicting house prices in this dataset due to its superior accuracy and ability to handle complex patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7865a4-70a6-4c4e-98dd-05449dd82ddb",
   "metadata": {},
   "source": [
    "<h3>5. Conclusion</h3>\n",
    "In this project, I explored several regression techniques to predict house prices in Ames. And found that:\n",
    "\n",
    " - Handling non-linear relationships is essential, as simpler models like Linear Regression struggled with the data complexity.\n",
    " - Ensemble methods (Random Forest and Gradient Boosting) provided the best performance, with Gradient Boosting emerging as the top model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d638aa-ac45-4bc8-bbcd-2e926a89043e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
